## PCA for Feature Selection and Classification on MNIST Dataset

üîç Explore the power of Principal Component Analysis (PCA) for feature selection and classification on the MNIST dataset!

### Description

üìä This program takes you through the following engaging steps:

**1. Dataset Acquisition:**
 Download the MNIST dataset from the Kaggle repository. üì•
   [MNIST Dataset](https://www.kaggle.com/datasets/scolianni/mnistasjpg)

**2. Data Preparation:**
 Load the image dataset into the program's environment and convert it into a suitable format for creating a machine learning model.

**3. Custom PCA Implementation:**
 Implement PCA from scratch by defining a custom PCA function or class. No pre-built implementations allowed! ‚úã
   The PCA implementation is designed to be flexible and work with any dataset.

**4. Feature Transformation and Classification:**
 Use k-Nearest Neighbors (kNN) algorithm to train ML models on the training set using both the original features and the transformed features obtained from PCA. 
   Experiment with different numbers of Principal Components (PCs): 5, 25, and 125.

**5. Model Evaluation:**
 Run the trained models on the test set and report the classification accuracies achieved.

**6. Explained Variance Analysis:**
 Plot the explained variance (ratio of eigenvalue and sum of all eigenvalues) against the number of PCs.
   Discover the minimum number of PCs needed to cover at least 80% of the variance.

### Usage

Follow these steps to embark on your PCA journey:

1. Download the MNIST dataset from the provided link: [MNIST Dataset](https://www.kaggle.com/datasets/scolianni/mnistasjpg)
2. Prepare your programming environment and ensure the required dependencies are installed.
3. Load the downloaded image dataset into the program.
4. Implement the custom PCA function or class.
5. Train the kNN models on the training set using both the original and transformed features.
6. Evaluate the trained models on the test set and calculate the classification accuracies.
7. Plot the explained variance versus the number of PCs and determine the minimum number of PCs needed to cover at least 80% of the variance.

üöÄ Note: The program assumes that you have basic knowledge of programming and machine learning concepts.
